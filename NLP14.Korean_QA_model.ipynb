{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ckonlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경에 맞게 경로 적절히 수정\n",
    "DATA_DIR = os.getenv('HOME')+'/aiffel/babi_memory_net'\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train_kor.txt\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test_kor.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 필웅이는 화장실로 갔습니다.\n",
      "2 은경이는 복도로 이동했습니다.\n",
      "3 필웅이는 어디야? \t화장실\t1\n",
      "4 수종이는 복도로 복귀했습니다.\n",
      "5 경임이는 정원으로 갔습니다.\n",
      "6 수종이는 어디야? \t복도\t4\n",
      "7 은경이는 사무실로 갔습니다.\n",
      "8 경임이는 화장실로 뛰어갔습니다.\n",
      "9 수종이는 어디야? \t복도\t4\n",
      "10 필웅이는 복도로 갔습니다.\n",
      "11 수종이는 사무실로 가버렸습니다.\n",
      "12 수종이는 어디야? \t사무실\t11\n",
      "13 은경이는 정원으로 복귀했습니다.\n",
      "14 은경이는 침실로 갔습니다.\n",
      "15 경임이는 어디야? \t화장실\t8\n",
      "1 경임이는 사무실로 가버렸습니다.\n",
      "2 경임이는 화장실로 이동했습니다.\n",
      "3 경임이는 어디야? \t화장실\t2\n",
      "4 필웅이는 침실로 이동했습니다.\n",
      "5 수종이는 복도로 갔습니다.\n"
     ]
    }
   ],
   "source": [
    "# 20개 문장 출력\n",
    "i = 0\n",
    "lines = open(TRAIN_FILE , \"rb\")\n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()\n",
    "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "        \n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_stories))\n",
    "print(len(train_questions))\n",
    "print(len(train_answers))\n",
    "print(len(test_stories))\n",
    "print(len(test_questions))\n",
    "print(len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['수종이는 화장실로 뛰어갔습니다.',\n",
       " '경임이는 사무실로 갔습니다.',\n",
       " '은경이는 부엌으로 이동했습니다.',\n",
       " '경임이는 화장실로 갔습니다.',\n",
       " '수종이는 복도로 갔습니다.',\n",
       " '필웅이는 부엌으로 가버렸습니다.',\n",
       " '수종이는 부엌으로 이동했습니다.',\n",
       " '수종이는 화장실로 가버렸습니다.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stories[3878]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['필웅이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '경임이는 어디야? ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['화장실', '복도', '복도', '사무실', '화장실']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "\n",
    "[Customized Konlpy 사용하기](https://inspiringpeople.github.io/data%20analysis/ckonlpy/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "twitter = Twitter()\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.add_dictionary('필웅이', 'Noun')\n",
    "twitter.add_dictionary('수종이', 'Noun')\n",
    "twitter.add_dictionary('경임이', 'Noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return twitter.morphs(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "    \n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "    \n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어장 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석 후 불용어 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 함수를 사용하여 단어장과 가장 긴 샘플의 길이를 리턴 \n",
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'는': 1, '.': 2, '로': 3, '했습니다': 4, '으로': 5, '경임이': 6, '은경이': 7, '수종이': 8, '필웅이': 9, '이동': 10, '가버렸습니다': 11, '뛰어갔습니다': 12, '복귀': 13, '화장실': 14, '정원': 15, '복도': 16, '갔습니다': 17, '사무실': 18, '부엌': 19, '침실': 20, '어디': 21, '야': 22, '?': 23}\n"
     ]
    }
   ],
   "source": [
    "# 단어장 출력\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩을 고려하여 단어장 +1\n",
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스토리의 최대 길이 : 70\n",
      "질문의 최대 길이 : 5\n"
     ]
    }
   ],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "    # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "    # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 70) (10000, 5) (10000, 24) (1000, 70) (1000, 5) (1000, 24)\n"
     ]
    }
   ],
   "source": [
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어에서의 모델 정확도 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크 횟수\n",
    "train_epochs = 120\n",
    "# 배치 크기\n",
    "batch_size = 32\n",
    "# 임베딩 크기\n",
    "embed_size = 50\n",
    "# LSTM의 크기\n",
    "lstm_size = 64\n",
    "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
    "dropout_rate = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories : Tensor(\"input_1:0\", shape=(None, 70), dtype=float32)\n",
      "Question: Tensor(\"input_2:0\", shape=(None, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 입력을 담아두는 변수 정의\n",
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    " \n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embed_size) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    " \n",
    "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embed_size) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input encoded m Tensor(\"sequential/dropout/cond/Identity:0\", shape=(None, 70, 50), dtype=float32)\n",
      "Input encoded c Tensor(\"sequential_1/dropout_1/cond/Identity:0\", shape=(None, 70, 5), dtype=float32)\n",
      "Question encoded Tensor(\"sequential_2/dropout_2/cond/Identity:0\", shape=(None, 5, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "print('Question encoded', question_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match shape Tensor(\"activation/truediv:0\", shape=(None, 70, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response shape Tensor(\"permute/transpose:0\", shape=(None, 5, 70), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 매칭 유사도 행렬과 질문에 대한 임베딩을 더한다.\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_maxlen)\n",
    "print('Response shape', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer shape Tensor(\"concatenate/concat:0\", shape=(None, 5, 120), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    " \n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.8923 - acc: 0.1753 - val_loss: 1.7968 - val_acc: 0.1580\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6856 - acc: 0.2715 - val_loss: 1.5477 - val_acc: 0.3290\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5306 - acc: 0.3595 - val_loss: 1.5692 - val_acc: 0.3370\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4853 - acc: 0.3855 - val_loss: 1.4441 - val_acc: 0.4160\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4664 - acc: 0.4102 - val_loss: 1.4043 - val_acc: 0.4430\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4111 - acc: 0.4527 - val_loss: 1.3256 - val_acc: 0.4880\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3517 - acc: 0.4714 - val_loss: 1.3081 - val_acc: 0.4930\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3214 - acc: 0.4932 - val_loss: 1.2880 - val_acc: 0.5060\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2883 - acc: 0.4980 - val_loss: 1.2596 - val_acc: 0.5150\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2530 - acc: 0.5103 - val_loss: 1.2241 - val_acc: 0.4980\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2263 - acc: 0.5154 - val_loss: 1.1982 - val_acc: 0.5220\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2014 - acc: 0.5209 - val_loss: 1.2041 - val_acc: 0.5170\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1874 - acc: 0.5244 - val_loss: 1.1889 - val_acc: 0.5090\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1735 - acc: 0.5267 - val_loss: 1.1795 - val_acc: 0.5320\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1589 - acc: 0.5265 - val_loss: 1.1804 - val_acc: 0.5120\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1564 - acc: 0.5257 - val_loss: 1.1700 - val_acc: 0.5220\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1486 - acc: 0.5314 - val_loss: 1.1702 - val_acc: 0.5170\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1324 - acc: 0.5330 - val_loss: 1.1795 - val_acc: 0.5140\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1288 - acc: 0.5329 - val_loss: 1.1590 - val_acc: 0.5180\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1181 - acc: 0.5393 - val_loss: 1.1568 - val_acc: 0.5150\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1081 - acc: 0.5411 - val_loss: 1.1638 - val_acc: 0.5170\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1051 - acc: 0.5423 - val_loss: 1.1817 - val_acc: 0.5160\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0960 - acc: 0.5431 - val_loss: 1.1670 - val_acc: 0.4990\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0928 - acc: 0.5422 - val_loss: 1.1482 - val_acc: 0.5180\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0809 - acc: 0.5440 - val_loss: 1.1796 - val_acc: 0.5140\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0684 - acc: 0.5572 - val_loss: 1.1629 - val_acc: 0.5200\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0678 - acc: 0.5587 - val_loss: 1.1832 - val_acc: 0.4990\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0477 - acc: 0.5640 - val_loss: 1.1518 - val_acc: 0.5270\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0276 - acc: 0.5820 - val_loss: 1.1154 - val_acc: 0.5550\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9489 - acc: 0.6275 - val_loss: 0.9849 - val_acc: 0.6340\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8131 - acc: 0.7000 - val_loss: 0.7985 - val_acc: 0.7220\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6570 - acc: 0.7651 - val_loss: 0.6989 - val_acc: 0.7290\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5984 - acc: 0.7801 - val_loss: 0.6836 - val_acc: 0.7420\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5576 - acc: 0.7942 - val_loss: 0.6258 - val_acc: 0.7580\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5160 - acc: 0.8115 - val_loss: 0.5566 - val_acc: 0.7910\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4437 - acc: 0.8388 - val_loss: 0.5023 - val_acc: 0.8160\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3916 - acc: 0.8590 - val_loss: 0.4461 - val_acc: 0.8350\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3581 - acc: 0.8715 - val_loss: 0.4345 - val_acc: 0.8410\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3313 - acc: 0.8754 - val_loss: 0.4245 - val_acc: 0.8380\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3094 - acc: 0.8847 - val_loss: 0.4213 - val_acc: 0.8440\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3040 - acc: 0.8895 - val_loss: 0.4013 - val_acc: 0.8560\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2857 - acc: 0.8946 - val_loss: 0.3467 - val_acc: 0.8600\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2685 - acc: 0.9021 - val_loss: 0.3595 - val_acc: 0.8600\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2475 - acc: 0.9087 - val_loss: 0.3745 - val_acc: 0.8630\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2362 - acc: 0.9140 - val_loss: 0.3100 - val_acc: 0.8820\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2174 - acc: 0.9233 - val_loss: 0.2750 - val_acc: 0.8920\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2021 - acc: 0.9276 - val_loss: 0.2773 - val_acc: 0.9010\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1820 - acc: 0.9372 - val_loss: 0.2496 - val_acc: 0.9150\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1631 - acc: 0.9429 - val_loss: 0.2252 - val_acc: 0.9200\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1538 - acc: 0.9476 - val_loss: 0.1967 - val_acc: 0.9340\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1374 - acc: 0.9522 - val_loss: 0.1851 - val_acc: 0.9380\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1284 - acc: 0.9557 - val_loss: 0.1904 - val_acc: 0.9380\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1253 - acc: 0.9570 - val_loss: 0.1723 - val_acc: 0.9410\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1119 - acc: 0.9616 - val_loss: 0.2166 - val_acc: 0.9260\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1087 - acc: 0.9625 - val_loss: 0.1573 - val_acc: 0.9490\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1003 - acc: 0.9663 - val_loss: 0.1790 - val_acc: 0.9470\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0948 - acc: 0.9674 - val_loss: 0.1649 - val_acc: 0.9510\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0893 - acc: 0.9696 - val_loss: 0.1700 - val_acc: 0.9450\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0869 - acc: 0.9709 - val_loss: 0.1595 - val_acc: 0.9540\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0795 - acc: 0.9728 - val_loss: 0.1781 - val_acc: 0.9490\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0757 - acc: 0.9745 - val_loss: 0.1634 - val_acc: 0.9470\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0770 - acc: 0.9742 - val_loss: 0.1831 - val_acc: 0.9490\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0693 - acc: 0.9775 - val_loss: 0.1671 - val_acc: 0.9500\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0671 - acc: 0.9778 - val_loss: 0.1867 - val_acc: 0.9460\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0629 - acc: 0.9808 - val_loss: 0.1670 - val_acc: 0.9430\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0602 - acc: 0.9794 - val_loss: 0.1644 - val_acc: 0.9480\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0553 - acc: 0.9818 - val_loss: 0.2211 - val_acc: 0.9470\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0584 - acc: 0.9803 - val_loss: 0.1675 - val_acc: 0.9500\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0531 - acc: 0.9831 - val_loss: 0.1525 - val_acc: 0.9550\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0503 - acc: 0.9840 - val_loss: 0.1749 - val_acc: 0.9480\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0483 - acc: 0.9838 - val_loss: 0.1438 - val_acc: 0.9580\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0489 - acc: 0.9832 - val_loss: 0.1778 - val_acc: 0.9500\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0420 - acc: 0.9851 - val_loss: 0.1523 - val_acc: 0.9560\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0460 - acc: 0.9857 - val_loss: 0.1510 - val_acc: 0.9560\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0387 - acc: 0.9868 - val_loss: 0.1679 - val_acc: 0.9580\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0411 - acc: 0.9877 - val_loss: 0.1513 - val_acc: 0.9590\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0352 - acc: 0.9881 - val_loss: 0.1599 - val_acc: 0.9550\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0388 - acc: 0.9869 - val_loss: 0.1263 - val_acc: 0.9610\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0322 - acc: 0.9895 - val_loss: 0.1519 - val_acc: 0.9640\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0278 - acc: 0.9904 - val_loss: 0.1231 - val_acc: 0.9660\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0372 - acc: 0.9888 - val_loss: 0.1343 - val_acc: 0.9630\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0303 - acc: 0.9908 - val_loss: 0.1315 - val_acc: 0.9620\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0307 - acc: 0.9898 - val_loss: 0.1549 - val_acc: 0.9590\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0331 - acc: 0.9896 - val_loss: 0.1385 - val_acc: 0.9570\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0268 - acc: 0.9907 - val_loss: 0.1436 - val_acc: 0.9560\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0325 - acc: 0.9898 - val_loss: 0.1419 - val_acc: 0.9600\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0305 - acc: 0.9916 - val_loss: 0.1413 - val_acc: 0.9630\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0283 - acc: 0.9908 - val_loss: 0.1189 - val_acc: 0.9630\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0195 - acc: 0.9940 - val_loss: 0.1484 - val_acc: 0.9600\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0234 - acc: 0.9924 - val_loss: 0.1087 - val_acc: 0.9700\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0225 - acc: 0.9936 - val_loss: 0.1157 - val_acc: 0.9680\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0227 - acc: 0.9929 - val_loss: 0.1317 - val_acc: 0.9640\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0205 - acc: 0.9943 - val_loss: 0.1202 - val_acc: 0.9660\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0231 - acc: 0.9925 - val_loss: 0.1287 - val_acc: 0.9600\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0189 - acc: 0.9939 - val_loss: 0.1055 - val_acc: 0.9740\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0280 - acc: 0.9922 - val_loss: 0.1052 - val_acc: 0.9690\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0169 - acc: 0.9955 - val_loss: 0.0883 - val_acc: 0.9710\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0197 - acc: 0.9928 - val_loss: 0.1382 - val_acc: 0.9620\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0179 - acc: 0.9936 - val_loss: 0.0942 - val_acc: 0.9690\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0247 - acc: 0.9934 - val_loss: 0.1328 - val_acc: 0.9650\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0200 - acc: 0.9944 - val_loss: 0.1198 - val_acc: 0.9660\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0207 - acc: 0.9931 - val_loss: 0.0977 - val_acc: 0.9760\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0189 - acc: 0.9944 - val_loss: 0.0846 - val_acc: 0.9710\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0190 - acc: 0.9941 - val_loss: 0.1185 - val_acc: 0.9730\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0172 - acc: 0.9948 - val_loss: 0.1075 - val_acc: 0.9720\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0137 - acc: 0.9953 - val_loss: 0.1308 - val_acc: 0.9690\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0198 - acc: 0.9944 - val_loss: 0.0913 - val_acc: 0.9710\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0144 - acc: 0.9955 - val_loss: 0.1240 - val_acc: 0.9720\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0167 - acc: 0.9959 - val_loss: 0.1209 - val_acc: 0.9670\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.1069 - val_acc: 0.9720\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0188 - acc: 0.9943 - val_loss: 0.1044 - val_acc: 0.9700\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0836 - val_acc: 0.9770\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0147 - acc: 0.9956 - val_loss: 0.1200 - val_acc: 0.9710\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0171 - acc: 0.9945 - val_loss: 0.0846 - val_acc: 0.9760\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0134 - acc: 0.9956 - val_loss: 0.0829 - val_acc: 0.9770\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 0.9970 - val_loss: 0.0758 - val_acc: 0.9750\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0150 - acc: 0.9959 - val_loss: 0.0708 - val_acc: 0.9760\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0160 - acc: 0.9960 - val_loss: 0.0871 - val_acc: 0.9750\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0176 - acc: 0.9951 - val_loss: 0.0731 - val_acc: 0.9830\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0161 - acc: 0.9950 - val_loss: 0.0737 - val_acc: 0.9740\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    " \n",
    "# 테스트 데이터를 검증 데이터로 사용하면서 모델 훈련 시작\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    " \n",
    "# 훈련 후에는 모델 저장\n",
    "model_path = os.getenv('HOME')+'/aiffel/babi_memory_net/model_ko.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0737 - acc: 0.9740\n",
      "\n",
      " 테스트 정확도: 0.9740\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문                |실제값  |예측값\n",
      "---------------------------------------\n",
      "은경이 는 어디 야 ?        : 복도      복도\n",
      "필웅이 는 어디 야 ?        : 화장실     화장실\n",
      "경임이 는 어디 야 ?        : 부엌      부엌\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 부엌      부엌\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 정원      정원\n",
      "수종이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 사무실     사무실\n",
      "수종이 는 어디 야 ?        : 사무실     사무실\n",
      "필웅이 는 어디 야 ?        : 부엌      부엌\n",
      "필웅이 는 어디 야 ?        : 정원      정원\n",
      "수종이 는 어디 야 ?        : 사무실     사무실\n",
      "필웅이 는 어디 야 ?        : 침실      침실\n",
      "필웅이 는 어디 야 ?        : 침실      침실\n",
      "은경이 는 어디 야 ?        : 부엌      부엌\n",
      "은경이 는 어디 야 ?        : 정원      정원\n",
      "은경이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 사무실     사무실\n",
      "은경이 는 어디 야 ?        : 부엌      복도\n",
      "필웅이 는 어디 야 ?        : 복도      복도\n",
      "은경이 는 어디 야 ?        : 사무실     사무실\n",
      "은경이 는 어디 야 ?        : 사무실     사무실\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "수종이 는 어디 야 ?        : 침실      침실\n",
      "경임이 는 어디 야 ?        : 침실      침실\n",
      "필웅이 는 어디 야 ?        : 침실      침실\n",
      "수종이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 부엌      부엌\n"
     ]
    }
   ],
   "source": [
    "NUM_DISPLAY = 30\n",
    "\n",
    "print(\"{:18}|{:5}|{}\".format(\"질문\", \"실제값\", \"예측값\"))\n",
    "print(39 * \"-\")\n",
    "\n",
    "for i in range(NUM_DISPLAY):\n",
    "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
    "    label = idx2word[ytest[i]]\n",
    "    prediction = idx2word[ytest_[i]]\n",
    "    print(\"{:20}: {:7} {}\".format(question, label, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 총평\n",
    "\n",
    "- 한국어에서도 정확도가 97%정도 나왔다\n",
    "- 토큰화 konlpy의 Twitter의 형태소 분석기의 성능이 좋은 것으로 보인다. \n",
    "- 불용어 제거가 없이도 정확도가 만족할 만한 수준으로 나왔다.  \n",
    "- 임의의 30개 질문에 대해 정확도 29/30을 보였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
